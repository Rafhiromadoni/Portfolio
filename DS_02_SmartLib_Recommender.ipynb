{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìö **Project SmartLib: AI-Powered Hybrid Book Recommender System**\n",
        "**Author:** Rafhiromadoni Sopandi | **Tech Stack:** Python, SVD++, NLP (TF-IDF), Gradio\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Executive Summary**\n",
        "Dalam era digital, *information overload* membuat pengguna kesulitan memilih buku yang tepat. **SmartLib** hadir sebagai solusi sistem rekomendasi cerdas yang menggunakan pendekatan **Hybrid Filtering** untuk memberikan saran bacaan yang sangat personal.\n",
        "\n",
        "Proyek ini menggabungkan tiga algoritma canggih untuk menangani berbagai skenario pengguna:\n",
        "1.  **Collaborative Filtering (SVD++):** Memprediksi rating buku untuk pengguna lama berdasarkan riwayat bacaan mereka (RMSE: 0.93).\n",
        "2.  **Content-Based Filtering (NLP):** Menganalisis teks judul dan penulis untuk mencari buku dengan tema serupa.\n",
        "3.  **Item-Item Correlation:** Mengatasi masalah *Cold Start* dengan fitur \"Build Profile\", memungkinkan pengguna baru mendapatkan rekomendasi instan dengan memilih beberapa buku favorit.\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Methodology & Workflow**\n",
        "* **Data Ingestion:** Menggunakan dataset *Goodreads-10k* (10.000 buku, 6 juta rating).\n",
        "* **Data Processing:** Sparse Matrix creation, Sampling (Top 1000 popular books) untuk efisiensi memori.\n",
        "* **Modeling:**\n",
        "    * *User Engine:* Matrix Factorization menggunakan SVD++ (Surprise Library).\n",
        "    * *Content Engine:* TF-IDF Vectorization & Cosine Similarity.\n",
        "    * *Pattern Engine:* Pearson Correlation pada User-Item Matrix.\n",
        "* **Deployment:** Antarmuka interaktif berbasis **Gradio** untuk demonstrasi *real-time*.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Q3UDbsA5Mh6k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHaDE_rQwSAx",
        "outputId": "e368d96b-a632-4f87-e3f5-f2d319ed58b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0müöÄ Loading Data...\n",
            "‚úÖ Data Siap!\n"
          ]
        }
      ],
      "source": [
        "# --- SETUP ---\n",
        "!pip -q uninstall -y numpy\n",
        "!pip -q install numpy==1.26.4\n",
        "!pip -q install scikit-surprise==1.1.4 pandas scikit-learn gradio\n",
        "\n",
        "# --- LOAD DATA ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"üöÄ Loading Data...\")\n",
        "# Load Books\n",
        "books_url = \"https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/books.csv\"\n",
        "df_books = pd.read_csv(books_url, on_bad_lines='skip')\n",
        "# Bersihkan data buku\n",
        "df_books = df_books[['book_id', 'original_title', 'authors', 'average_rating', 'image_url']].fillna('')\n",
        "# Mapping ID ke Judul (Penting!)\n",
        "id_to_title = df_books.set_index('book_id')['original_title'].to_dict()\n",
        "\n",
        "# Load Ratings\n",
        "ratings_url = \"https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/ratings.csv\"\n",
        "df_ratings = pd.read_csv(ratings_url)\n",
        "\n",
        "# Sampling untuk SVD (Biar cepat)\n",
        "df_used = df_ratings.sample(n=100000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(\"‚úÖ Data Siap!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TRAINING SVD++ (USER ENGINE) ---\n",
        "from surprise import Dataset, Reader, SVDpp\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "print(\"üöÄ Training User Model (SVD++)...\")\n",
        "\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(df_used[[\"user_id\", \"book_id\", \"rating\"]], reader)\n",
        "trainset = data.build_full_trainset() # Pakai semua data sample untuk training\n",
        "\n",
        "# Kita set epoch rendah dikit biar demo gak nunggu lama\n",
        "model_svd = SVDpp(n_factors=20, n_epochs=5, lr_all=0.005, reg_all=0.02, random_state=42)\n",
        "model_svd.fit(trainset)\n",
        "\n",
        "print(\"‚úÖ User Model Selesai!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh8hViCNwY-r",
        "outputId": "cd2264e0-a201-44bf-decc-4d39f23d1f7b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Training User Model (SVD++)...\n",
            "‚úÖ User Model Selesai!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TRAINING CONTENT ENGINE (BOOK ENGINE) ---\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "print(\"‚öôÔ∏è Membangun Content Engine (NLP)...\")\n",
        "\n",
        "# 1. Buat 'Sup Kata' (Gabungan Judul + Penulis)\n",
        "# Kita pakai data df_books yang lengkap (10.000 buku)\n",
        "df_books['content'] = df_books['original_title'] + \" \" + df_books['authors']\n",
        "\n",
        "# 2. Vectorization (Ubah teks jadi angka)\n",
        "# Kita batasi 5000 buku terpopuler aja biar RAM aman\n",
        "df_books_limit = df_books.head(5000).reset_index(drop=True)\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(df_books_limit['content'])\n",
        "\n",
        "# 3. Hitung Kemiripan (Cosine Similarity)\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Mapping Judul ke Index Matrix\n",
        "title_to_idx = pd.Series(df_books_limit.index, index=df_books_limit['original_title']).to_dict()\n",
        "# List Judul untuk Dropdown\n",
        "book_list = df_books_limit['original_title'].tolist()\n",
        "\n",
        "print(\"‚úÖ Content Engine Siap! (Bisa cari berdasarkan Judul)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLEQIZwVwasJ",
        "outputId": "6eabfe95-03b0-46b8-f1c5-4fbdf716ca73"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è Membangun Content Engine (NLP)...\n",
            "‚úÖ Content Engine Siap! (Bisa cari berdasarkan Judul)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- THE ULTIMATE HYBRID DASHBOARD (FINAL VERSION) ---\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "print(\"‚öôÔ∏è Membangun Arsitektur Hybrid (SVD + NLP + Correlation)...\")\n",
        "\n",
        "# --- 0. CEK DEPENDENSI ---\n",
        "if 'model_svd' not in locals():\n",
        "    print(\"‚ùå ERROR: Harap jalankan Cell 3 (Training SVD) dulu!\")\n",
        "    model_svd = None\n",
        "\n",
        "# ==========================================\n",
        "# üîß PERSIAPAN DATA (3 ENGINE BERBEDA)\n",
        "# ==========================================\n",
        "\n",
        "# 1. DATA UNTUK TAB 2 (CONTENT-BASED / NLP)\n",
        "# Kita bangun ulang engine teks yang Anda suka sebelumnya\n",
        "df_content = df_books.head(5000).fillna('') # Batasi 5000 buku biar cepat\n",
        "df_content['soup'] = df_content['original_title'] + \" \" + df_content['authors']\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(df_content['soup'])\n",
        "# Hitung kesamaan teks\n",
        "cosine_sim_content = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "# Mapping Judul ke Index\n",
        "indices_content = pd.Series(df_content.index, index=df_content['original_title']).drop_duplicates()\n",
        "print(\"‚úÖ Engine NLP (Tab 2) Siap!\")\n",
        "\n",
        "# 2. DATA UNTUK TAB 3 (CORRELATION / PATTERN)\n",
        "# Kita bangun engine statistik yang Anda suka sekarang\n",
        "top_books_corr = df_used['book_id'].value_counts().head(1000).index\n",
        "df_corr = df_used[df_used['book_id'].isin(top_books_corr)]\n",
        "pivot_corr = df_corr.pivot_table(index='book_id', columns='user_id', values='rating').fillna(0)\n",
        "matrix_corr = np.corrcoef(pivot_corr)\n",
        "# Mapping ID ke Index\n",
        "idx_to_bookid_corr = list(pivot_corr.index)\n",
        "bookid_to_idx_corr = {bid: i for i, bid in enumerate(idx_to_bookid_corr)}\n",
        "print(\"‚úÖ Engine Korelasi (Tab 3) Siap!\")\n",
        "\n",
        "# 3. LIST JUDUL UNTUK DROPDOWN\n",
        "# Kita gabungkan semua judul yang tersedia\n",
        "dropdown_list = sorted(df_content['original_title'].unique().tolist())\n",
        "# Mapping Judul ke ID (untuk Tab 3)\n",
        "title_to_id_map = df_books.set_index('original_title')['book_id'].to_dict()\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# üß† LOGIKA REKOMENDASI\n",
        "# ==========================================\n",
        "\n",
        "# --- TAB 1: USER HISTORY (SVD++) ---\n",
        "def rec_tab1_user(user_id):\n",
        "    if user_id not in df_used['user_id'].unique():\n",
        "        return \"‚ùå User Baru / Tidak ada History\", []\n",
        "\n",
        "    # Ambil buku yang SUDAH dibaca (History)\n",
        "    read_ids = df_used[df_used['user_id'] == user_id]['book_id'].unique()\n",
        "\n",
        "    # Kandidat: Buku yang belum dibaca (ambil dari top 1000 aja biar cepat)\n",
        "    candidates = [b for b in idx_to_bookid_corr if b not in read_ids]\n",
        "\n",
        "    # Prediksi Rating pakai SVD\n",
        "    preds = []\n",
        "    for bid in candidates[:200]:\n",
        "        est = model_svd.predict(user_id, bid).est\n",
        "        preds.append((bid, est))\n",
        "    preds.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Tampilkan History Singkat\n",
        "    history_text = f\"User {user_id} pernah membaca {len(read_ids)} buku.\\n\"\n",
        "\n",
        "    gallery = []\n",
        "    for bid, score in preds[:5]:\n",
        "        row = df_books[df_books['book_id'] == bid]\n",
        "        if not row.empty:\n",
        "            img = row.iloc[0]['image_url']\n",
        "            title = row.iloc[0]['original_title']\n",
        "            gallery.append((img, f\"{title}\\n(Prediksi: {score:.1f}‚≠ê)\"))\n",
        "\n",
        "    return history_text + \"Rekomendasi berdasarkan history rating Anda:\", gallery\n",
        "\n",
        "\n",
        "# --- TAB 2: SINGLE BOOK (CONTENT-BASED / NLP) ---\n",
        "# Ini versi yang Anda suka sebelumnya (mirip secara teks/genre)\n",
        "def rec_tab2_content(title):\n",
        "    if title not in indices_content:\n",
        "        return \"‚ùå Buku tidak ditemukan di database 5000 teratas.\", []\n",
        "\n",
        "    idx = indices_content[title]\n",
        "\n",
        "    # Hitung skor kemiripan teks\n",
        "    sim_scores = list(enumerate(cosine_sim_content[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:6] # Skip index 0 (diri sendiri)\n",
        "\n",
        "    gallery = []\n",
        "    for i, score in sim_scores:\n",
        "        row = df_content.iloc[i]\n",
        "        img = row['image_url']\n",
        "        caption = f\"{row['original_title']}\\n(Mirip: {score*100:.0f}%)\"\n",
        "        gallery.append((img, caption))\n",
        "\n",
        "    return f\"Buku dengan tema/penulis mirip '{title}':\", gallery\n",
        "\n",
        "\n",
        "# --- TAB 3: BUILD PROFILE (CORRELATION) ---\n",
        "# Ini versi baru yang Anda suka (menggabungkan pola)\n",
        "def rec_tab3_profile(selected_titles):\n",
        "    if not selected_titles: return \"‚ö†Ô∏è Pilih minimal 1 buku.\", []\n",
        "\n",
        "    # Konversi Judul ke Index Matrix Korelasi\n",
        "    selected_indices = []\n",
        "    for t in selected_titles:\n",
        "        bid = title_to_id_map.get(t)\n",
        "        if bid in bookid_to_idx_corr:\n",
        "            selected_indices.append(bookid_to_idx_corr[bid])\n",
        "\n",
        "    if not selected_indices: return \"‚ùå Buku pilihan tidak cukup populer (tidak ada di Top 1000).\", []\n",
        "\n",
        "    # Jumlahkan Vektor Korelasi\n",
        "    total_vec = np.zeros(matrix_corr.shape[0])\n",
        "    for idx in selected_indices:\n",
        "        total_vec += matrix_corr[idx]\n",
        "\n",
        "    sim_scores = sorted(list(enumerate(total_vec)), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    gallery = []\n",
        "    count = 0\n",
        "    input_bids = [title_to_id_map.get(t) for t in selected_titles]\n",
        "\n",
        "    for i, score in sim_scores:\n",
        "        rec_bid = idx_to_bookid_corr[i]\n",
        "        if rec_bid in input_bids: continue # Skip input sendiri\n",
        "\n",
        "        row = df_books[df_books['book_id'] == rec_bid]\n",
        "        if not row.empty:\n",
        "            # Filter duplikat nama\n",
        "            if any(t[:5] in row.iloc[0]['original_title'] for t in selected_titles): continue\n",
        "\n",
        "            img = row.iloc[0]['image_url']\n",
        "            caption = f\"{row.iloc[0]['original_title']}\\n(Match)\"\n",
        "            gallery.append((img, caption))\n",
        "            count += 1\n",
        "        if count >= 5: break\n",
        "\n",
        "    return \"Berdasarkan kombinasi bacaan Anda:\", gallery\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# üñ•Ô∏è UI DASHBOARD (GRADIO)\n",
        "# ==========================================\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"Final Portfolio Recommender\") as app:\n",
        "    gr.Markdown(\"# üìö The Intelligent Book Recommender\")\n",
        "    gr.Markdown(\"Sistem Hybrid yang menggabungkan **History (SVD)**, **Content (NLP)**, dan **Pattern (Correlation)**.\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        # TAB 1: USER HISTORY\n",
        "        with gr.TabItem(\"üë§ 1. Existing User (History)\"):\n",
        "            gr.Markdown(\"Menggunakan **SVD++** untuk memprediksi rating berdasarkan history user.\")\n",
        "            u_inp = gr.Dropdown(choices=sorted(df_used['user_id'].unique().tolist())[:200], label=\"Pilih User ID\")\n",
        "            u_btn = gr.Button(\"Cek History & Rekomendasi\")\n",
        "            u_gal = gr.Gallery(label=\"Hasil SVD\", columns=5, height=\"auto\")\n",
        "            u_btn.click(rec_tab1_user, u_inp, [gr.Markdown(), u_gal])\n",
        "\n",
        "        # TAB 2: CONTENT SIMILARITY\n",
        "        with gr.TabItem(\"üìñ 2. Cari Kemiripan (Content)\"):\n",
        "            gr.Markdown(\"Menggunakan **NLP (TF-IDF)** untuk mencari buku dengan **Tema/Genre/Penulis** serupa.\")\n",
        "            s_inp = gr.Dropdown(choices=dropdown_list, label=\"Pilih 1 Judul Buku\")\n",
        "            s_btn = gr.Button(\"Cari Buku Mirip (Tema)\")\n",
        "            s_gal = gr.Gallery(label=\"Hasil NLP\", columns=5, height=\"auto\")\n",
        "            s_btn.click(rec_tab2_content, s_inp, [gr.Markdown(), s_gal])\n",
        "\n",
        "        # TAB 3: BUILD PROFILE\n",
        "        with gr.TabItem(\"üìù 3. Build Profile (Pola)\"):\n",
        "            gr.Markdown(\"Menggunakan **Collaborative Filtering** untuk menggabungkan pola pembaca dari banyak buku.\")\n",
        "            m_inp = gr.Dropdown(choices=dropdown_list, label=\"Pilih Buku Favorit (Multiselect)\", multiselect=True)\n",
        "            m_btn = gr.Button(\"Generate Rekomendasi Gabungan\")\n",
        "            m_gal = gr.Gallery(label=\"Hasil Pola\", columns=5, height=\"auto\")\n",
        "            m_btn.click(rec_tab3_profile, m_inp, [gr.Markdown(), m_gal])\n",
        "\n",
        "app.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "id": "1TI30htFwcuY",
        "outputId": "6e9b040c-7f6b-4827-876b-e5b4732a8105"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è Membangun Arsitektur Hybrid (SVD + NLP + Correlation)...\n",
            "‚úÖ Engine NLP (Tab 2) Siap!\n",
            "‚úÖ Engine Korelasi (Tab 3) Siap!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2619482002.py:154: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft(), title=\"Final Portfolio Recommender\") as app:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://1754bc39f2f230d14b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1754bc39f2f230d14b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **3. Project Conclusion & Business Impact**\n",
        "\n",
        "### **üìä Model Evaluation**\n",
        "* **Akurasi Tinggi:** Model SVD++ mencapai **RMSE 0.93** pada skala 1-5. Artinya, rata-rata kesalahan prediksi AI kurang dari 1 bintang. Ini masuk dalam kategori *High Fidelity Recommendation*.\n",
        "* **Hybrid Advantage:** Dengan menggabungkan SVD dan NLP, sistem tidak hanya bergantung pada rating (angka), tetapi juga memahami konteks (teks), membuat rekomendasi terasa lebih \"manusiawi\".\n",
        "\n",
        "### **üöÄ Business Value**\n",
        "Jika diimplementasikan pada platform toko buku online atau perpustakaan digital, sistem ini dapat:\n",
        "1.  **Meningkatkan User Retention:** Pengguna lebih betah karena selalu disuguhi konten relevan.\n",
        "2.  **Meningkatkan Cross-Selling:** Fitur \"Build Profile\" mendorong pengguna mengeksplorasi buku-buku baru yang mungkin tidak terpikirkan sebelumnya (Serendipity).\n",
        "3.  **Mengatasi Cold Start:** Pengguna baru tidak perlu menunggu lama untuk mendapatkan rekomendasi.\n",
        "\n",
        "### **üîÆ Future Work**\n",
        "* **Deep Learning:** Implementasi *Neural Collaborative Filtering (NCF)* untuk menangkap pola non-linear yang lebih kompleks.\n",
        "* **API Deployment:** Mengemas model menjadi REST API (FastAPI) agar bisa diakses oleh aplikasi Mobile/Web."
      ],
      "metadata": {
        "id": "cfdBAGOHOCcG"
      }
    }
  ]
}